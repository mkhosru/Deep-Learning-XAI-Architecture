# -*- coding: utf-8 -*-
"""Digital_tools.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Zv72YKCCl0bfhjhFdtWixlwIky2iciW
"""

import os

from google.colab import drive
drive.mount('/content/drive')

data_path = "/content/drive/MyDrive/Colab Notebooks/archive1"

print("Files/folders inside dataset:")
print(os.listdir(data_path)[:20])  # show first 20 entries

import os, random, numpy as np, torch

SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", device)

data_path = "/content/drive/MyDrive/Colab Notebooks/archive1"
train_dir = f"{data_path}/train"
test_dir  = f"{data_path}/test"

from sklearn.model_selection import StratifiedShuffleSplit
from pathlib import PurePath
import shutil, os

train_dir = f"{data_path}/train"
val_dir   = f"{data_path}/val"
IMG_EXT = {".jpg",".jpeg",".png",".bmp",".tif",".tiff"}

if not os.path.exists(val_dir):
    os.makedirs(val_dir, exist_ok=True)
    classes = [c for c in sorted(os.listdir(train_dir))
               if os.path.isdir(os.path.join(train_dir, c))]

    X, y = [], []
    for c in classes:
        paths = [os.path.join(train_dir, c, f)
                 for f in os.listdir(os.path.join(train_dir, c))
                 if os.path.splitext(f)[1].lower() in IMG_EXT]
        # need at least 2 samples per class for a split
        if len(paths) < 2:
            print(f"Skipping class '{c}' (only {len(paths)} image).")
            continue
        X += paths
        y += [c]*len(paths)

    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)
    idx_train, idx_val = next(sss.split(X, y))
    X_val = [X[i] for i in idx_val]

    for src in X_val:
        cls = PurePath(src).parent.name
        dst_dir = os.path.join(val_dir, cls)
        os.makedirs(dst_dir, exist_ok=True)
        shutil.move(src, os.path.join(dst_dir, os.path.basename(src)))

    print("Validation split created at:", val_dir)
else:
    print("â„¹val/ already exists; skipping split.")

from sklearn.model_selection import StratifiedShuffleSplit
from pathlib import Path, PurePath
import shutil, os

val_dir = f"{data_path}/val"
if not os.path.exists(val_dir):
    os.makedirs(val_dir, exist_ok=True)
    classes = sorted(os.listdir(train_dir))
    X, y = [], []
    for c in classes:
        imgs = [str(PurePath(train_dir, c, f)) for f in os.listdir(os.path.join(train_dir,c))]
        X += imgs; y += [c]*len(imgs)

    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)
    idx_train, idx_val = next(sss.split(X, y))
    X_val = [X[i] for i in idx_val]
    # move val files into val/<class>/
    for p in X_val:
        cls = PurePath(p).parent.name
        os.makedirs(os.path.join(val_dir, cls), exist_ok=True)
        shutil.move(p, os.path.join(val_dir, cls, PurePath(p).name))

import timm, torch
from torch.utils.data import DataLoader
from torchvision import transforms, datasets

IMG_SIZE = 224
BATCH    = 32

train_tfms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(0.1,0.1,0.1,0.05),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
])

val_tfms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
])

train_ds = datasets.ImageFolder(train_dir, transform=train_tfms)
val_ds   = datasets.ImageFolder(f"{data_path}/val", transform=val_tfms)
test_ds  = datasets.ImageFolder(test_dir, transform=val_tfms)

train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=2, pin_memory=True)
val_dl   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)
test_dl  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)

CLASSES = train_ds.classes; NUM_CLASSES = len(CLASSES); CLASSES

#pip install --upgrade timm

def build_model(model_name="resnet50", pretrained=True, num_classes=NUM_CLASSES):
    model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)
    return model.to(device)

# options:
#   "resnet50"
#   "vit_base_patch16_224"
#   "tf_efficientnetv2_s"
model_name = "resnet50"  # change to vit_base_patch16_224 or tf_efficientnetv2_s for other runs

#pretrained model
model = build_model(model_name)

#training from scratch
#model = build_model(model_name, pretrained=False)

!pip install torchmetrics==1.3.2 -q

import os, time
from pathlib import Path
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm



EPOCHS = 10
LR     = 2e-4
WD     = 1e-4

criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)
scaler    = torch.cuda.amp.GradScaler(enabled=(device=="cuda"))

# ---- set up logging ----
timestamp = time.strftime("%Y%m%d-%H%M%S")
log_dir   = Path("/content/drive/MyDrive")
log_dir.mkdir(parents=True, exist_ok=True)
log_path  = log_dir / f"{model_name}_training_log_{timestamp}.txt"

with open(log_path, "w") as f:
    f.write("# Training log\n")
    f.write(f"# model_name\t{model_name}\n")
    f.write(f"# epochs\t{EPOCHS}\n")
    f.write(f"# lr\t{LR}\n")
    f.write(f"# weight_decay\t{WD}\n")
    f.write("# epoch\ttrain_loss\ttrain_acc\tval_loss\tval_acc\tcheckpoint\n")

best_val_acc, patience, bad = 0.0, 8, 0

for epoch in range(1, EPOCHS+1):
    # -------------------
    # Train
    # -------------------
    model.train()
    train_loss_sum, train_correct, train_count = 0.0, 0, 0
    for x, y in tqdm(train_dl, desc=f"Epoch {epoch} [train]"):
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad(set_to_none=True)
        with torch.cuda.amp.autocast(enabled=(device=="cuda")):
            logits = model(x)
            loss   = criterion(logits, y)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        batch_size = x.size(0)
        train_loss_sum += loss.item() * batch_size
        train_correct  += (logits.argmax(1) == y).sum().item()
        train_count    += batch_size

    train_loss = train_loss_sum / max(1, train_count)
    train_acc  = train_correct  / max(1, train_count)

    # -------------------
    # Validation
    # -------------------
    model.eval()
    val_loss_sum, val_correct, val_count = 0.0, 0, 0
    with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device=="cuda")):
        for x, y in tqdm(val_dl, desc=f"Epoch {epoch} [val]", leave=False):
            x, y = x.to(device), y.to(device)
            logits = model(x)
            loss   = criterion(logits, y)

            batch_size = x.size(0)
            val_loss_sum += loss.item() * batch_size
            val_correct  += (logits.argmax(1) == y).sum().item()
            val_count    += batch_size

    val_loss = val_loss_sum / max(1, val_count)
    val_acc  = val_correct  / max(1, val_count)

    print(f"Epoch {epoch:02d} | train_loss {train_loss:.4f} acc {train_acc:.4f} | "
          f"val_loss {val_loss:.4f} acc {val_acc:.4f}")

    checkpoint_path = ""  # default (no save)
    if val_acc > best_val_acc:
        best_val_acc, bad = float(val_acc), 0
        # NEW: checkpoint file includes epoch + accuracy
        checkpoint_path = log_dir / f"{model_name}_best_epoch{epoch:02d}_acc{val_acc:.4f}.pth"
        torch.save(model.state_dict(), checkpoint_path)
    else:
        bad += 1
        if bad >= patience:
            print("Early stopping.")
            break

    # log per epoch with checkpoint info (if saved)
    with open(log_path, "a") as f:
        f.write(f"{epoch}\t{train_loss:.6f}\t{train_acc:.6f}\t{val_loss:.6f}\t{val_acc:.6f}\t{checkpoint_path}\n")

# ---- wrap up
with open(log_path, "a") as f:
    f.write("# training_finished\t1\n")
    f.write(f"# best_val_acc\t{best_val_acc:.6f}\n")

print(f"Metrics log saved to: {log_path}")
print(f"Best model path: {checkpoint_path if checkpoint_path else 'No improvement saved'}")



# ===== Test evaluation (append to same log) =====
import torch
from torchmetrics.classification import (
    MulticlassAccuracy,
    MulticlassPrecision,
    MulticlassRecall,
    MulticlassF1Score,
    MulticlassConfusionMatrix
)

# If you tracked the best path during training, ensure it's here:
# best_ckpt_path is set whenever a new best is found; if not defined, fall back to last checkpoint_path
try:
    best_ckpt_path
except NameError:
    best_ckpt_path = str(log_dir / f"{model_name}_best.pth")  # fallback

# Load best checkpoint for testing
if best_ckpt_path and Path(best_ckpt_path).exists():
    model.load_state_dict(torch.load(best_ckpt_path, map_location=device))
else:
    print(f"[WARN] Best checkpoint not found at: {best_ckpt_path}. Using current model weights.")

model.eval()

all_preds  = []
all_targets = []
with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device=="cuda")):
    for x, y in tqdm(test_dl, desc="Testing"):
        x = x.to(device)
        y = y.to(device)
        logits = model(x)
        preds  = logits.argmax(dim=1)
        all_preds.append(preds.detach().cpu())
        all_targets.append(y.detach().cpu())

y_pred = torch.cat(all_preds, dim=0)
y_true = torch.cat(all_targets, dim=0)

# --- Metrics ---
acc_metric   = MulticlassAccuracy(num_classes=NUM_CLASSES)
prec_micro   = MulticlassPrecision(num_classes=NUM_CLASSES, average='micro')
rec_micro    = MulticlassRecall(num_classes=NUM_CLASSES, average='micro')
f1_micro     = MulticlassF1Score(num_classes=NUM_CLASSES, average='micro')

prec_macro   = MulticlassPrecision(num_classes=NUM_CLASSES, average='macro')
rec_macro    = MulticlassRecall(num_classes=NUM_CLASSES, average='macro')
f1_macro     = MulticlassF1Score(num_classes=NUM_CLASSES, average='macro')

prec_weight  = MulticlassPrecision(num_classes=NUM_CLASSES, average='weighted')
rec_weight   = MulticlassRecall(num_classes=NUM_CLASSES, average='weighted')
f1_weight    = MulticlassF1Score(num_classes=NUM_CLASSES, average='weighted')

# Per-class (arrays of length NUM_CLASSES)
prec_percls  = MulticlassPrecision(num_classes=NUM_CLASSES, average=None)
rec_percls   = MulticlassRecall(num_classes=NUM_CLASSES, average=None)
f1_percls    = MulticlassF1Score(num_classes=NUM_CLASSES, average=None)

# Confusion matrix
cm_metric    = MulticlassConfusionMatrix(num_classes=NUM_CLASSES)

test_acc      = acc_metric(y_pred, y_true).item()
test_prec_mi  = prec_micro(y_pred, y_true).item()
test_rec_mi   = rec_micro(y_pred, y_true).item()
test_f1_mi    = f1_micro(y_pred, y_true).item()

test_prec_ma  = prec_macro(y_pred, y_true).item()
test_rec_ma   = rec_macro(y_pred, y_true).item()
test_f1_ma    = f1_macro(y_pred, y_true).item()

test_prec_w   = prec_weight(y_pred, y_true).item()
test_rec_w    = rec_weight(y_pred, y_true).item()
test_f1_w     = f1_weight(y_pred, y_true).item()

percls_prec   = prec_percls(y_pred, y_true).tolist()
percls_rec    = rec_percls(y_pred, y_true).tolist()
percls_f1     = f1_percls(y_pred, y_true).tolist()

cm            = cm_metric(y_pred, y_true).to(torch.int64).tolist()

# Resolve class labels (optional)
try:
    class_labels = list(map(str, class_names))  # must be iterable of length NUM_CLASSES
    if len(class_labels) != NUM_CLASSES:
        raise ValueError
except Exception:
    class_labels = [f"class_{i}" for i in range(NUM_CLASSES)]

# --- Append to the same log file ---
with open(log_path, "a") as f:
    f.write("# test_results\n")
    f.write(f"# best_ckpt_used\t{best_ckpt_path}\n")
    f.write(f"test_accuracy\t{test_acc:.6f}\n")

    f.write("test_precision_micro\t{:.6f}\n".format(test_prec_mi))
    f.write("test_recall_micro\t{:.6f}\n".format(test_rec_mi))
    f.write("test_f1_micro\t{:.6f}\n".format(test_f1_mi))

    f.write("test_precision_macro\t{:.6f}\n".format(test_prec_ma))
    f.write("test_recall_macro\t{:.6f}\n".format(test_rec_ma))
    f.write("test_f1_macro\t{:.6f}\n".format(test_f1_ma))

    f.write("test_precision_weighted\t{:.6f}\n".format(test_prec_w))
    f.write("test_recall_weighted\t{:.6f}\n".format(test_rec_w))
    f.write("test_f1_weighted\t{:.6f}\n".format(test_f1_w))

    f.write("# per_class_metrics\t(label\tprecision\trecall\tf1)\n")
    for idx, (lbl, p, r, s) in enumerate(zip(class_labels, percls_prec, percls_rec, percls_f1)):
        f.write(f"{idx}\t{lbl}\t{p:.6f}\t{r:.6f}\t{s:.6f}\n")

    f.write("# confusion_matrix_rows_are_true_cols_are_pred\n")
    for row in cm:
        f.write("\t".join(map(str, row)) + "\n")

print(f"Test metrics appended to: {log_path}")

!pip install grad-cam

import random, numpy as np
from PIL import Image
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image
from pytorch_grad_cam.utils.reshape_transforms import vit_reshape_transform

# 1) choose a real test image
#img_path, _ = random.choice(test_ds.sample30
img_path = "/content/drive/MyDrive/Colab Notebooks/archive1/test/363.jpg"
print("Using test image:", img_path)
raw = Image.open(img_path).convert("RGB").resize((IMG_SIZE, IMG_SIZE))
inp = val_tfms(raw).unsqueeze(0).to(device)   # device already 'cuda'

# 2) pick target layer by model type
if "resnet" in model_name:
    target_layers = [model.layer4[-1]]           # last ResNet block
    reshape_transform = None
elif "efficientnet" in model_name:
    target_layers = [model.conv_head]
    reshape_transform = None
elif "vit" in model_name:
    target_layers = [model.blocks[-1].norm1]     # ViT block norm
    reshape_transform = vit_reshape_transform
else:
    target_layers = [list(model.children())[-2]]
    reshape_transform = None

# 3) build CAM object (NOTE: no 'use_cuda' kwarg)
cam = GradCAM(model=model, target_layers=target_layers,
              reshape_transform=reshape_transform)

# 4) forward + target class
with torch.no_grad():
    probs = model(inp).softmax(1)
pred_cls = int(probs.argmax(1).item())
targets = [ClassifierOutputTarget(pred_cls)]

# 5) compute and visualize CAM
grayscale_cam = cam(input_tensor=inp, targets=targets, eigen_smooth=True)[0]
rgb_img = np.array(raw) / 255.0
vis = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)
display(Image.fromarray(vis))
Image.fromarray(vis).save("/content/drive/MyDrive/Colab Notebooks/Gradcam/gradcam_example.png")

# 4) forward + target class
with torch.no_grad():
    probs = model(inp).softmax(1)
pred_cls = int(probs.argmax(1).item())
targets = [ClassifierOutputTarget(pred_cls)]

# --- Print per-class probabilities (nice, human-readable) ---
# Use the same class order as your datasets.ImageFolder
class_names = CLASSES  # this was defined earlier: CLASSES = train_ds.classes
p = probs[0].detach().cpu()

# NEW: Sort class-probability pairs by probability in descending order
sorted_probs = sorted(zip(class_names, p.tolist()), key=lambda x: x[1], reverse=True)

print("\nPredicted Class Probabilities (sorted):")
for name, pr in sorted_probs:
    print(f"{name:<15}: {pr*100:.2f}%")  # show as percentage

# NEW: Pick top-1 class and confidence
top_class, top_prob = sorted_probs[0]
print(f"\nFinal Prediction: {top_class} (confidence = {top_prob*100:.2f}%)")

# NEW: Use top_class for Grad-CAM target
pred_cls = class_names.index(top_class)
targets = [ClassifierOutputTarget(pred_cls)]

!pip install lime

from lime import lime_image
from skimage.segmentation import mark_boundaries
import numpy as np

def predict_np(imgs):
    # imgs: list of HxWx3 uint8
    batch = []
    for im in imgs:
        im = Image.fromarray(im).resize((IMG_SIZE, IMG_SIZE))
        t  = val_tfms(im)  # same normalization
        batch.append(t.numpy())
    batch = torch.tensor(np.stack(batch)).to(device)
    with torch.no_grad():
        probs = model(batch).softmax(1).cpu().numpy()
    return probs

explainer = lime_image.LimeImageExplainer()
img_np = np.array(raw)
explanation = explainer.explain_instance(img_np, predict_np, top_labels=1, hide_color=0, num_samples=1000)
label = explanation.top_labels[0]
temp, mask = explanation.get_image_and_mask(label, positive_only=True, num_features=5, hide_rest=False)
#Image.fromarray((mark_boundaries(temp, mask)*255).astype(np.uint8))
#SAVE THE IMAGE
Image.fromarray((mark_boundaries(temp, mask) * 255).astype(np.uint8)).save(
    "/content/drive/MyDrive/Colab Notebooks/Gradcam/lime_example.png")